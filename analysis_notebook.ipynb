{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of a Convolutional Neural Network Architecture\n",
    "Course project for the class _IoT Based Smart Systems_, carried out by _Riccardo Maria Pesce_ during Academic Year _2021-2022_, under the kind supervision of Professor _Maurizio Palesi_.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Motivation\n",
    "With the latest scientific and technological advancements that has taken place in the past few years, AI techniques have been employed in different fields, with great success. \n",
    "\n",
    "While Deep Learning Models are still trained on the cloud (using state-of-the-art computing machines with specialized hardware such as _GPU_ or _TPU_), it is becoming always more common to perform inference on the edge, i.e. on the devices itself, so as to reduce latency and optimize the usage of bandwith, a relevant issue for constrained devices.\n",
    "\n",
    "### Objective\n",
    "The objective of this thesis is to analyze a _CNN_ (Convolutional Neural Network) architecture performance on a constrained hardware, seeing how the mapping will affect the performance in terms of throughput and energy consumption.\n",
    "In particular, these performance achievements are obtained in the following ways:\n",
    "\n",
    "* Through reducing data movements, since communication is more expensive than computation in terms of energy nowadays. We can reduce data movements by either reducing the number of times memory is accessed, employing for instance DRAM which are nearby the _PEs_ (Processing Elements), or else we can compress data to a smaller number bits to represent it, thus making data movements cheaper. From these observations, we notice how __memory is the main bottleneck__.\n",
    "\n",
    "* Maximizing PEs parallelism.\n",
    "\n",
    "### Mapping\n",
    "Mapping defines the order of execution of the MAC operations. The ordering can either be _temporal_ when operations are mapped serially on the same PE (i.e. the temporal order of execution), or _spatial_ when operations are mapped to multiple PE to execute in parallel.\n",
    "\n",
    "### Introduction to Timeloop and Accelergy\n",
    "In order to correctly design a DNN accelerator we need to cater for the different DNN architectures, and for each one of them we have to find an optimal mapping of these workloads onto specific hardware architectures.\n",
    "This is what Timeloop and Accelergy do, and in particular:\n",
    "* Timeloop generates a characterization of the energetical efficiency for each workload, through a mapper which finds the optimal way to plan operations on a specified architecture. To do so, Timeloop uses a coincise and unified representation of those core elements which are generally found in DNN accelerators.\n",
    "* Accelergy, on the basis of the above created characterization, provides a pretty good estimate of energy consumption.\n",
    "\n",
    "For a more complete introduction to Timeloop/Accelergy, please refer to [the official website](http://accelergy.mit.edu/tutorial.html).\n",
    "\n",
    "## Simulation\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this thesis, we want to find an efficient mapping of the _ResNet-50_ model onto different architectures.\n",
    "\n",
    "### ResNet-18\n",
    "\n",
    "We want to give a brief overview of the _ResNet-18_ architecture. \n",
    "\n",
    "![ResNet-18 Architecture](./assets/resnet18.png)\n",
    "\n",
    "The main key points, as highlighted in the above picture, are:\n",
    "\n",
    "* ResNet-18 architecture has __4 stages__.\n",
    "* Input height and width must be multiple of 32 and channel width must be equal to 3.\n",
    "* The main innovation of the ResNet architecture is the introduction of the _Identity Connection_ which allows the input feature map of some layer to skip some blocks and being summed to the output feature map of the skipped layers, before passing through the activation function (which is commonly the _ReLU_). This is a very succesful strategy to improve accuracy, thanks to the fact that we limit the _vanishing gradient_ problem which often occurs in very deep neural networks.\n",
    "* ResNet uses Batch Normalization to mitigate the _Covariance Shift_ problem.\n",
    "\n",
    "For a better understanding, please check out the original paper on [ArXiv](https://arxiv.org/abs/1512.03385).\n",
    "\n",
    "\n",
    "### Accelerator architecture\n",
    "\n",
    "We are going to try the ResNet-18 workload on different hardware architectures. In particular we are going to analyze energy consumption, inferences per second and occupied area.\n",
    "\n",
    "We start with a basic architecture, which will contain a main memory, a global buffer and multiple processing elements. The features of each one of the elements will be changed, and for each configuration statistics will be shown.\n",
    "\n",
    "Regarding the mapper, it can be found [here](./ResNet18/mapper/mapper.yaml). We are using eight threads in parallel, to find the best parameters to optimize _delay_ and _energy_, using a _random-pruned_ algorithms which will stop once it finds 50 configurations which perform worse than the optimal one found. \n",
    "\n",
    "#### Configuration 1\n",
    "\n",
    "First architecture will use a 45nm technology as follows:\n",
    "* __Main Memory__: DRAM memory with `width = 512`, `block-size = 64` and `word-bits = 8`.\n",
    "* __Global Buffer__: SRAM memory with `depth = 12`, `width = 16`, `block-size = 16` and `word-bits = 1`.\n",
    "* __Processing Elements (16)__: made up of\n",
    "    * __Register File__: with `depth = 16`, `width = 8`, `block-size = 1` and `word-bits = 8`.\n",
    "    * __MACC (intmac)__: with `data-width = 16`.\n",
    "\n",
    "Let's now run the simulation, remembering to __spin up Docker__ as we are using Timeloop/Accelergy through it. Also, we will use _python_ to run all the simulations for each layer automatically. We are opening a terminal window, where we are starting the container using the command `docker-compose run --rm exercises`. After this, we are putting the `ResNet18` folder inside the newly created `workspace` folder. With the below snippet of code we are generating the bash file which will be run inside the container shell to run the simulations for this first configuration and all the layers. Before running, you might need to run `chmod u+x bash_script.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "configurations = [f for f in glob.glob(\"workspace/ResNet18/arch/*\") if f.endswith(\".yaml\")]\n",
    "conf_names = [f.replace(\"workspace/ResNet18/arch/\", \"\").replace(\".yaml\", \"\") for f in configurations]\n",
    "\n",
    "conf = \"workspace/ResNet18/arch/configuration1.yaml\"\n",
    "conf_name = \"configuration1\"\n",
    "\n",
    "with open(\"workspace/bash_script.sh\", \"w\") as bash_script:\n",
    "    bash_script.write(\"#!/bin/bash\")\n",
    "    bash_script.write(\"\\n\\n\")\n",
    "    bash_script.write(\"chmod -R 777 .\")\n",
    "    bash_script.write(\"\\n\\n\")\n",
    "    Path(f\"workspace/ResNet18/output/conf-{conf_name}/\").mkdir(mode=777, exist_ok=True)\n",
    "    Path(f\"workspace/ResNet18/output/conf-{conf_name}/\").chmod(0o777)\n",
    "    for i in range(1, 22):\n",
    "        Path(f\"workspace/ResNet18/output/conf-{conf_name}/output{i}/\").mkdir(mode=777, exist_ok=True)\n",
    "        cmd = \"timeloop-mapper \" + conf.replace(\"workspace/\", \"\") + \" ResNet18/arch/components/*.yaml ResNet18/prob/resnet18_layer\"+ str(i) + \".yaml ResNet18/mapper/mapper.yaml ResNet18/constraints/*.yaml -o ./ResNet18/output/conf-\" + conf_name + \"/output\" + str(i)\n",
    "        bash_script.write(cmd)\n",
    "        bash_script.write(\"\\n\\n\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some functions to parse the different statistics per layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_energy_breakdown_from_stats_txt(file_path):\n",
    "  data = dict()\n",
    "  with open(file_path, \"r\") as f:\n",
    "    stats = f.read()\n",
    "    for m in re.findall(r\"\\b(?!\\bMACCs|Total\\b)([a-zA-Z<>=]+)\\s+=\\s+(?=.*[1-9])(\\d+.\\d+)\", stats):\n",
    "      data[m[0]] = float(m[1])\n",
    "    f.close()\n",
    "  return data\n",
    "\n",
    "def get_area_breakdown_from_stats_txt(file_path):\n",
    "  data = dict()\n",
    "  with open(file_path, \"r\") as f:\n",
    "    stats = f.read()\n",
    "    for m in re.findall(r\"=== ([a-zA-Z]+) ===.*?Area .*?\\s+:\\s(\\d+.\\d+)\", stats, re.DOTALL):\n",
    "      if m[1] != \"1.00\":\n",
    "        data[m[0]] = float(m[1])\n",
    "    f.close()\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see the energy consumption per MACC (computation). Remember that it is calculated as __pj/MACC__ as we are estimating the energy for each __MACC__ operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MACC</th>\n",
       "      <th>RegisterFile</th>\n",
       "      <th>MainMemory</th>\n",
       "      <th>GlobalBuffer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>40.44</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.11</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>32.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.40</td>\n",
       "      <td>19.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>32.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>32.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>36.39</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>14.07</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>48.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.41</td>\n",
       "      <td>41.17</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>68.21</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.42</td>\n",
       "      <td>37.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>68.21</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.26</td>\n",
       "      <td>68.21</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.32</td>\n",
       "      <td>16.93</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MACC  RegisterFile  MainMemory  GlobalBuffer\n",
       "1   0.56          0.26       40.44          0.00\n",
       "2   0.56          0.26       48.78          0.00\n",
       "3   0.56          0.26       48.78          0.00\n",
       "4   0.56          0.26       48.78          0.00\n",
       "5   0.56          0.26       48.78          0.00\n",
       "6   0.56          0.26       48.11          0.00\n",
       "7   0.56          0.26       32.39          0.00\n",
       "8   0.56          0.40       19.33          0.00\n",
       "9   0.56          0.26       32.39          0.00\n",
       "10  0.56          0.26       32.39          0.00\n",
       "11  0.56          0.42       36.39          0.00\n",
       "12  0.56          0.26       48.19          0.00\n",
       "13  0.56          0.41       14.07          0.00\n",
       "14  0.56          0.26       48.19          0.00\n",
       "15  0.56          0.26       48.19          0.00\n",
       "16  0.56          0.41       41.17          0.00\n",
       "17  0.56          0.26       68.21          0.00\n",
       "18  0.56          0.42       37.06          0.00\n",
       "19  0.56          0.26       68.21          0.00\n",
       "20  0.56          0.26       68.21          0.00\n",
       "21  0.56          0.32       16.93          0.03"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pj_macc_stats(output_path):\n",
    "    layer_paths = [f for f in glob.glob(output_path + \"/*/\" + \"timeloop-mapper.stats.txt\")]\n",
    "    layers = [int(f.replace(output_path, \"\")\n",
    "               .replace(\"timeloop-mapper.stats.txt\", \"\")\n",
    "               .replace(\"/\", \"\")\n",
    "               .replace(\"output\", \"\")) for f in layer_paths]\n",
    "\n",
    "    stats = {layer: get_energy_breakdown_from_stats_txt(layer_path) for layer, layer_path in zip(layers, layer_paths)}\n",
    "    stats_df = pd.DataFrame(stats).T.sort_index().fillna(0)\n",
    "\n",
    "    return stats_df, stats_df.sum(axis=0), stats_df.sum(axis=1)\n",
    "\n",
    "pj_macc_stats, pj_macc_total_by_element, pj_macc_total_by_layer = pj_macc_stats(\"workspace/ResNet18/output/conf-configuration1\")\n",
    "pj_macc_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how much energy per MACC has been consumed by each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     41.26\n",
       "2     49.60\n",
       "3     49.60\n",
       "4     49.60\n",
       "5     49.60\n",
       "6     48.93\n",
       "7     33.21\n",
       "8     20.29\n",
       "9     33.21\n",
       "10    33.21\n",
       "11    37.37\n",
       "12    49.01\n",
       "13    15.04\n",
       "14    49.01\n",
       "15    49.01\n",
       "16    42.14\n",
       "17    69.03\n",
       "18    38.04\n",
       "19    69.03\n",
       "20    69.03\n",
       "21    17.84\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pj_macc_total_by_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get the main whole statistics for each layer, remembering that __area is calculated as um<sup>2</sup>__ and this time energy is calculated as __uJ__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Energy\n",
      "1   4868.83\n",
      "2   5734.05\n",
      "3   5734.05\n",
      "4   5734.05\n",
      "5   5734.05\n",
      "6   2828.41\n",
      "7   3839.29\n",
      "8    130.29\n",
      "9   3839.29\n",
      "10  3839.29\n",
      "11  2160.27\n",
      "12  5666.49\n",
      "13    96.61\n",
      "14  5666.49\n",
      "15  5666.49\n",
      "16  2435.82\n",
      "17  7980.19\n",
      "18   244.30\n",
      "19  7980.19\n",
      "20  7980.19\n",
      "21  4675.94\n",
      "---------\n",
      "Total:  92834.58\n"
     ]
    }
   ],
   "source": [
    "def get_summary_stats(file_path):\n",
    "  data = dict()\n",
    "  with open(file_path, \"r\") as f:\n",
    "    stats = f.read()\n",
    "    initial_index = stats.index(\"Utilization:\")\n",
    "    end_index = stats.index(\"\\n\\nMACCs\")\n",
    "    cleaned = [c.replace(\":\", \"\") for c in stats[initial_index:end_index + 1].split(\"\\n\") if c != \"\"]\n",
    "    summary = {s.split()[0]: float(s.split()[1]) for s in cleaned}\n",
    "    \n",
    "  return summary\n",
    "\n",
    "\n",
    "def energy_stats(output_path):\n",
    "  layer_paths = [f for f in glob.glob(output_path + \"/*/\" + \"timeloop-mapper.stats.txt\")]\n",
    "  layers = [int(f.replace(output_path, \"\")\n",
    "              .replace(\"timeloop-mapper.stats.txt\", \"\")\n",
    "              .replace(\"/\", \"\")\n",
    "              .replace(\"output\", \"\")) for f in layer_paths]\n",
    "\n",
    "  stats = {layer: {\"Energy\": get_summary_stats(layer_path)[\"Energy\"]} for layer, layer_path in zip(layers, layer_paths)}\n",
    "  stats_df = pd.DataFrame(stats).T.sort_index().fillna(0)\n",
    "\n",
    "  return stats_df, stats_df.sum(axis=0).values.tolist()[0]\n",
    "\n",
    "energy_by_layer, energy_total = energy_stats(\"workspace/ResNet18/output/conf-configuration1\")\n",
    "print(energy_by_layer)\n",
    "print(\"---------\")\n",
    "print(\"Total: \", energy_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ffbd1b0996e3a79afb3d81e30644170a5904f770a23d1ec65a6a61c4dfe8e95"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
